{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adf1Copydata"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/pipeline9metaData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "datasetDelimitedText1",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"columnCount",
								"exists",
								"itemName",
								"structure",
								"lastModified"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "If Condition1",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(\nformatDateTime(utcnow(),'DD-MM-YYYY'),\nformatDateTime(activity('Get Metadata1').output.lastModified,'DD-MM-YYYY'))",
								"type": "Expression"
							},
							"ifTrueActivities": [
								{
									"name": "Copy data1",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "DelimitedTextSource",
											"storeSettings": {
												"type": "AzureBlobFSReadSettings",
												"recursive": true,
												"enablePartitionDiscovery": false
											},
											"formatSettings": {
												"type": "DelimitedTextReadSettings"
											}
										},
										"sink": {
											"type": "DelimitedTextSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "DelimitedTextWriteSettings",
												"quoteAllText": true,
												"fileExtension": ".txt"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "datasetDelimitedText1",
											"type": "DatasetReference",
											"parameters": {}
										}
									],
									"outputs": [
										{
											"referenceName": "DelimitedText1",
											"type": "DatasetReference",
											"parameters": {}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-12-02T05:58:26Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DSSQLKeyvault')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "LSSQlAzureKeyVault",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow10Branch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable2forDataFlow",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowBranchDestAggr",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "DSDataFlowDestBranch",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"source(output(",
						"          deptno as integer,",
						"          dname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dept",
						"emp aggregate(groupBy(deptno),",
						"     TotalEmp = count(empid)) ~> aggregate1",
						"emp, dept join(emp@deptno == dept@deptno,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpDestBrancgAggr.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpDestBranchAll.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow12Pivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DsDataFlowDestPivot",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"emp pivot(groupBy(deptno),",
						"     pivotBy(salary),",
						"     CountofEmp = count(salary),",
						"     columnNaming: 'Sal$N$V_emp',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpDestdataFlowPivot.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow13Unpivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DSDataFlowVendorSourceUnpivot",
								"type": "DatasetReference"
							},
							"name": "Vendor"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowDestUnpivot",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          PO as string,",
						"          Vendor as string,",
						"          Apple as string,",
						"          Mango as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Vendor",
						"Vendor unpivot(output(",
						"          Fruits as string,",
						"          Quantity as string",
						"     ),",
						"     ungroupBy(PO,",
						"          Vendor),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string,",
						"          Column_3 as string,",
						"          Column_4 as string,",
						"          Column_5 as string",
						"     ),",
						"     partitionFileNames:['VendorDataFlowDestUnpivot.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14Serogaete')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DsDataFlowSourceSerogate",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DsDatFlowDestSerogate",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Ename as string,",
						"          Desig as string,",
						"          Sal as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp keyGenerate(output(empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          empid,",
						"          Ename,",
						"          Desig,",
						"          Sal",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpDataFlowDestSerogate.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15Window')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DSSQLDataFlowWindow",
								"type": "DatasetReference"
							},
							"name": "empdetails"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          country as string,",
						"          dept as string,",
						"          sal as double",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> empdetails",
						"empdetails window(over(dept),",
						"     desc(sal, true),",
						"     denseRank = denseRank()) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          country,",
						"          dept,",
						"          sal,",
						"          denseRank",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow16Alter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DSDataFlowEmpDetailsAlter",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSSQLDAtaFlowempDetailsAlter",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          country as string,",
						"          dept as string,",
						"          sal as double",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source1 alterRow(deleteIf(dept=='payrol'),",
						"     updateIf(dept=='HR')) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as integer,",
						"          name as string,",
						"          country as string,",
						"          dept as string,",
						"          sal as double",
						"     ),",
						"     deletable:true,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['id'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          country,",
						"          dept,",
						"          sal",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow17Flattern')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DSDataFlowEmpJson",
								"type": "DatasetReference"
							},
							"name": "empjson"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DsDataFlowJsondestEmpFlattern",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          contact as (emailAddress as string, phoneNumber as string),",
						"          employeeCode as string,",
						"          firstName as string,",
						"          jobTitleName as string,",
						"          lastName as string,",
						"          preferredFullName as string,",
						"          region as string,",
						"          skills as string[],",
						"          userId as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments') ~> empjson",
						"empjson foldDown(unroll(skills),",
						"     mapColumn(",
						"          employeeCode,",
						"          firstName,",
						"          jobTitleName,",
						"          lastName,",
						"          preferredFullName,",
						"          region,",
						"          skills,",
						"          userId",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          userId as string,",
						"          jobTitleName as string,",
						"          firstName as string,",
						"          lastName as string,",
						"          preferredFullName as string,",
						"          employeeCode as string,",
						"          region as string,",
						"          contact as (phoneNumber as string, emailAddress as string),",
						"          skills as string[]",
						"     ),",
						"     partitionFileNames:['empJsonflattern.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          employeeCode,",
						"          firstName,",
						"          jobTitleName,",
						"          lastName,",
						"          preferredFullName,",
						"          region,",
						"          skills,",
						"          userId",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow18Parameter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DsDataFlowSourceParameterEmp",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DsDataFlowDestParametrizeEMP",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     deptname as string",
						"}",
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          country as string,",
						"          dept as string,",
						"          sal as double",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     limit: 100,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"emp filter(dept==$deptname) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['empParametrizw.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1Join')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable2forDataFlow",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSdataFlowJoinDest",
								"type": "DatasetReference"
							},
							"name": "empjoindept"
						}
					],
					"transformations": [
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"source(output(",
						"          deptno as integer,",
						"          dname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dept",
						"emp, dept join(emp@deptno == dept@deptno,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empdeptjoin'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          ename,",
						"          deptno = emp@deptno,",
						"          salary,",
						"          dname",
						"     ),",
						"     partitionBy('hash', 1)) ~> empjoindept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow2Modify')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSdataFlowJoinDest",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "ModifyColumns1",
							"description": "Autogenerated by data preview actions"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> employee",
						"employee derive(ename = upper(ename)) ~> ModifyColumns1",
						"ModifyColumns1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empmodified'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow3Filter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowFilterDest",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source1 filter(equals(deptno, 10)) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empfilter'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow4Aggregate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowAggregateDest",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table',",
						"     partitionBy('hash', 1)) ~> employee",
						"employee aggregate(groupBy(deptno),",
						"     TotalEmployees = count(empid)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empaggregate'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5ConditionalSplit')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowAdminEmp",
								"type": "DatasetReference"
							},
							"name": "AdminSink"
						},
						{
							"dataset": {
								"referenceName": "DsDataFlowManagerDest",
								"type": "DatasetReference"
							},
							"name": "ManagerSinkk"
						}
					],
					"transformations": [
						{
							"name": "Admin"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"emp split(equals(deptno, 10),",
						"     equals(deptno, 20),",
						"     disjoint: false) ~> Admin@(Admin, Manager)",
						"Admin@Admin sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['adminEmp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          ename,",
						"          deptno,",
						"          salary",
						"     ),",
						"     partitionBy('hash', 1)) ~> AdminSink",
						"Admin@Manager sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ManagerEmp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          ename,",
						"          deptno,",
						"          salary",
						"     ),",
						"     partitionBy('hash', 1)) ~> ManagerSinkk"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5Join')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable2forDataFlow",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowEmpJoinDept",
								"type": "DatasetReference"
							},
							"name": "EmpJoinDept"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"source(output(",
						"          deptno as integer,",
						"          dname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dept",
						"emp aggregate(groupBy(deptno),",
						"     TotalEmployes = count(empid)) ~> aggregate1",
						"aggregate1, dept join(aggregate1@deptno == dept@deptno,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['empjoindept'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          deptno = dept@deptno,",
						"          dname,",
						"          TotalEmployes",
						"     ),",
						"     partitionBy('hash', 1)) ~> EmpJoinDept"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow6DerivedColumn')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowDerivedColumn",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> emp",
						"emp derive(ename = upper(ename),",
						"          Workstatus = iif(equals(deptno,10), 'Work', 'DontWork')) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string",
						"     ),",
						"     partitionFileNames:['EmpDerived.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow7Esits')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "Emp"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable2forDataFlow",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowDestExists",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> Emp",
						"source(output(",
						"          deptno as integer,",
						"          dname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> dept",
						"Emp, dept exists(Emp@deptno == dept@deptno,",
						"     negate:false,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpExists.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          ename,",
						"          deptno,",
						"          salary",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow8Union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DSDataFlowAdminEmp",
								"type": "DatasetReference"
							},
							"name": "Adminemp"
						},
						{
							"dataset": {
								"referenceName": "DsDataFlowManagerDest",
								"type": "DatasetReference"
							},
							"name": "ManagerEmp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSDataFlowDestUnion",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as short,",
						"          ename as string,",
						"          deptno as short,",
						"          salary as short,",
						"          Workstatus as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Adminemp",
						"source(output(",
						"          empid as short,",
						"          ename as string,",
						"          deptno as short,",
						"          salary as short,",
						"          Workstatus as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> ManagerEmp",
						"Adminemp, ManagerEmp union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpAllUnion.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow9Sort')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTableforDataFlow",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DSdataFlowSortbyNameDest",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "sortbyname"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          deptno as integer,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source1 sort(asc(ename, true),",
						"     caseInsensitive: true) ~> sortbyname",
						"sortbyname sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as string,",
						"          ename as string,",
						"          deptno as string,",
						"          salary as string,",
						"          Workstatus as string",
						"     ),",
						"     partitionFileNames:['EmpSortByname.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}